{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# LangChain: Evaluation\n",
    "\n",
    "## Outline:\n",
    "\n",
    "* Example generation\n",
    "* Manual evaluation (and debuging)\n",
    "* LLM-assisted evaluation\n",
    "* LangChain evaluation platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a56538",
   "metadata": {},
   "source": [
    "1. we need to have the chain or the application that we need to evaluate in the first place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945d8abb-ba55-40a4-a3c5-6ad0dab73e3e",
   "metadata": {},
   "source": [
    "Note: LLM's do not always produce the same results. When executing the code in your notebook, you may get slightly different answers that those in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24ff81cd-dce0-4344-8d45-4a98fd3a87c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28008949",
   "metadata": {},
   "source": [
    "## Create our QandA application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8deb1a",
   "metadata": {},
   "source": [
    "2. We are going to use Q&A application from L4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386b671d",
   "metadata": {},
   "source": [
    "3. we are going to load the same data that we were using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ec1106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'OutdoorClothingCatalog_1000.csv'\n",
    "loader = CSVLoader(file_path=file)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b3eeef",
   "metadata": {},
   "source": [
    "4. we are going to create the index with 1 line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b31c218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8fe4ce",
   "metadata": {},
   "source": [
    "5. and then we are going to create the retrieval QA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2006054",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0.0, model=llm_model)\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=index.vectorstore.as_retriever(), \n",
    "    verbose=True,\n",
    "    chain_type_kwargs = {\n",
    "        \"document_separator\": \"<<<<>>>>>\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791ebd73",
   "metadata": {},
   "source": [
    "### Coming up with test datapoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a319179",
   "metadata": {},
   "source": [
    "6. what are some data points we want to evaluate?\n",
    "- we are going to choose datapoints ourselves what we think are good examples\n",
    "    - come up with example question and example ground truth answer we evaluate\n",
    "- we are going to look at some examples to understand what is going on inside them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb04a0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\": 10\\nname: Cozy Comfort Pullover Set, Stripe\\ndescription: Perfect for lounging, this striped knit set lives up to its name. We used ultrasoft fabric and an easy design that's as comfortable at bedtime as it is when we have to make a quick run out.\\n\\nSize & Fit\\n- Pants are Favorite Fit: Sits lower on the waist.\\n- Relaxed Fit: Our most generous fit sits farthest from the body.\\n\\nFabric & Care\\n- In the softest blend of 63% polyester, 35% rayon and 2% spandex.\\n\\nAdditional Features\\n- Relaxed fit top with raglan sleeves and rounded hem.\\n- Pull-on pants have a wide elastic waistband and drawstring, side pockets and a modern slim leg.\\n\\nImported.\", metadata={'source': 'OutdoorClothingCatalog_1000.csv', 'row': 10})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe4a88c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=': 11\\nname: Ultra-Lofty 850 Stretch Down Hooded Jacket\\ndescription: This technical stretch down jacket from our DownTek collection is sure to keep you warm and comfortable with its full-stretch construction providing exceptional range of motion. With a slightly fitted style that falls at the hip and best with a midweight layer, this jacket is suitable for light activity up to 20° and moderate activity up to -30°. The soft and durable 100% polyester shell offers complete windproof protection and is insulated with warm, lofty goose down. Other features include welded baffles for a no-stitch construction and excellent stretch, an adjustable hood, an interior media port and mesh stash pocket and a hem drawcord. Machine wash and dry. Imported.', metadata={'source': 'OutdoorClothingCatalog_1000.csv', 'row': 11})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d548aef",
   "metadata": {},
   "source": [
    "### Hard-coded examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8022013",
   "metadata": {},
   "source": [
    "7. from the details above we create example Q&A pairs\n",
    "- this doesn't scale well, is there a way we can automate it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2d59bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Do the Cozy Comfort Pullover Set\\\n",
    "        have side pockets?\",\n",
    "        \"answer\": \"Yes\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What collection is the Ultra-Lofty \\\n",
    "        850 Stretch Down Hooded Jacket from?\",\n",
    "        \"answer\": \"The DownTek collection\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ce3e4f",
   "metadata": {},
   "source": [
    "### LLM-Generated examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fec50b",
   "metadata": {},
   "source": [
    "8. one of the ways to automate it is with language models themselves\n",
    "- we import the QA generation chain\n",
    "- it will take documents and create Q&A pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d44f8376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAGenerateChain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f83edef",
   "metadata": {},
   "source": [
    "9. it will do this using the LLM itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34e87816",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI(model=llm_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31fb5bd0-fc2a-478c-9a09-6fe7e3307241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the warning below can be safely ignored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259f6521",
   "metadata": {},
   "source": [
    "10. we will use the apply and parse method\n",
    "- this is applying the output parser to the result\n",
    "- because we want to get back the dictionary with Q&A pair, not just a string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eb2bff",
   "metadata": {},
   "source": [
    "Here i ran into problems:\n",
    "\n",
    "Chat GPT summary and fix:\n",
    "- Root cause: ChatOpenAI + QAGenerateChain tries to sum OpenAIObject token-usage fields → TypeError.\n",
    "- Fix: Use langchain.llms.OpenAI with gpt-3.5-turbo-instruct for the evaluator and pass d.page_content (strings), not Documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef7258",
   "metadata": {},
   "source": [
    "Course code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62abae09",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +=: 'OpenAIObject' and 'OpenAIObject'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m new_examples = \u001b[43mexample_gen_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply_and_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdoc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Endava-AI-Onboarding/langchain_course_2/.venv/lib/python3.11/site-packages/langchain/chains/llm.py:256\u001b[39m, in \u001b[36mLLMChain.apply_and_parse\u001b[39m\u001b[34m(self, input_list, callbacks)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_and_parse\u001b[39m(\n\u001b[32m    253\u001b[39m     \u001b[38;5;28mself\u001b[39m, input_list: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]], callbacks: Callbacks = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    254\u001b[39m ) -> Sequence[Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m    255\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call apply and then parse the results.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    257\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parse_result(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Endava-AI-Onboarding/langchain_course_2/.venv/lib/python3.11/site-packages/langchain/chains/llm.py:157\u001b[39m, in \u001b[36mLLMChain.apply\u001b[39m\u001b[34m(self, input_list, callbacks)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    156\u001b[39m     run_manager.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    158\u001b[39m outputs = \u001b[38;5;28mself\u001b[39m.create_outputs(response)\n\u001b[32m    159\u001b[39m run_manager.on_chain_end({\u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: outputs})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Endava-AI-Onboarding/langchain_course_2/.venv/lib/python3.11/site-packages/langchain/chains/llm.py:154\u001b[39m, in \u001b[36mLLMChain.apply\u001b[39m\u001b[34m(self, input_list, callbacks)\u001b[39m\n\u001b[32m    149\u001b[39m run_manager = callback_manager.on_chain_start(\n\u001b[32m    150\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m},\n\u001b[32m    151\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33minput_list\u001b[39m\u001b[33m\"\u001b[39m: input_list},\n\u001b[32m    152\u001b[39m )\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    156\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Endava-AI-Onboarding/langchain_course_2/.venv/lib/python3.11/site-packages/langchain/chains/llm.py:79\u001b[39m, in \u001b[36mLLMChain.generate\u001b[39m\u001b[34m(self, input_list, run_manager)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[32m     78\u001b[39m prompts, stop = \u001b[38;5;28mself\u001b[39m.prep_prompts(input_list, run_manager=run_manager)\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m     81\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Endava-AI-Onboarding/langchain_course_2/.venv/lib/python3.11/site-packages/langchain/chat_models/base.py:143\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    137\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    138\u001b[39m     prompts: List[PromptValue],\n\u001b[32m    139\u001b[39m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    140\u001b[39m     callbacks: Callbacks = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    141\u001b[39m ) -> LLMResult:\n\u001b[32m    142\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Endava-AI-Onboarding/langchain_course_2/.venv/lib/python3.11/site-packages/langchain/chat_models/base.py:92\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks)\u001b[39m\n\u001b[32m     90\u001b[39m     run_manager.on_llm_error(e)\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m llm_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_combine_llm_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mres\u001b[49m\u001b[43m.\u001b[49m\u001b[43mllm_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m generations = [res.generations \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[32m     94\u001b[39m output = LLMResult(generations=generations, llm_output=llm_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Endava-AI-Onboarding/langchain_course_2/.venv/lib/python3.11/site-packages/langchain/chat_models/openai.py:292\u001b[39m, in \u001b[36mChatOpenAI._combine_llm_outputs\u001b[39m\u001b[34m(self, llm_outputs)\u001b[39m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m token_usage.items():\n\u001b[32m    291\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m overall_token_usage:\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m         \u001b[43moverall_token_usage\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    294\u001b[39m         overall_token_usage[k] = v\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for +=: 'OpenAIObject' and 'OpenAIObject'"
     ]
    }
   ],
   "source": [
    "new_examples = example_gen_chain.apply_and_parse(\n",
    "    [{\"doc\": t} for t in data[:5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d953fa1d",
   "metadata": {},
   "source": [
    "chat gpt solution:\n",
    "1. Fix (stay on your pinned versions)\n",
    "- Use the completions wrapper OpenAI (instruct model) for the evaluator\n",
    "QAGenerateChain works fine with OpenAI in this version\n",
    "2. (Alternative) Keep ChatOpenAI but avoid the evaluator\n",
    "- If you must use ChatOpenAI, avoid QAGenerateChain.apply_and_parse on this stack (or upgrade LangChain, which you said you can’t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96849ee",
   "metadata": {},
   "source": [
    "11. we get a query and the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97ab28b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_examples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mnew_examples\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'new_examples' is not defined"
     ]
    }
   ],
   "source": [
    "new_examples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6903bb",
   "metadata": {},
   "source": [
    "12. let's check the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ebe4228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\": 0\\nname: Women's Campside Oxfords\\ndescription: This ultracomfortable lace-to-toe Oxford boasts a super-soft canvas, thick cushioning, and quality construction for a broken-in feel from the first time you put them on. \\n\\nSize & Fit: Order regular shoe size. For half sizes not offered, order up to next whole size. \\n\\nSpecs: Approx. weight: 1 lb.1 oz. per pair. \\n\\nConstruction: Soft canvas material for a broken-in feel and look. Comfortable EVA innersole with Cleansport NXT® antimicrobial odor control. Vintage hunt, fish and camping motif on innersole. Moderate arch contour of innersole. EVA foam midsole for cushioning and support. Chain-tread-inspired molded rubber outsole with modified chain-tread pattern. Imported. \\n\\nQuestions? Please contact us for any inquiries.\", metadata={'source': 'OutdoorClothingCatalog_1000.csv', 'row': 0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf25f2f",
   "metadata": {},
   "source": [
    "### Combine examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650d3c3b",
   "metadata": {},
   "source": [
    "13. add those examples in the examples we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ada2a3fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_examples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m examples += \u001b[43mnew_examples\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'new_examples' is not defined"
     ]
    }
   ],
   "source": [
    "examples += new_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ca86b",
   "metadata": {},
   "source": [
    "14. run an example through the chain and see what results it produces\n",
    "- we run the query and get an answer\n",
    "- limiting in things we can see: what is the prompt, what are the documents?\n",
    "- it is sometimes not enough just to see the final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9cdf5cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, the Cozy Comfort Pullover Set does have side pockets on the pull-on pants.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(examples[0][\"query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3cb08",
   "metadata": {},
   "source": [
    "## Manual Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97221995",
   "metadata": {},
   "source": [
    "15. if we set the debug utility it starts printing out a lot more information\n",
    "- often times there is a problem in the retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fcaf622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46597c63",
   "metadata": {},
   "source": [
    "16. it is printing out a lot more infor\n",
    "- retrieval\n",
    "- stuff\n",
    "- llm chain\n",
    "- question\n",
    "- context\n",
    "- what is entering the LLM\n",
    "- full prompt that is passed\n",
    "- human question\n",
    "- return time, token usage, model name\n",
    "- final response - side pockets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a142638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:RunTypeEnum.chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Do the Cozy Comfort Pullover Set        have side pockets?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:RunTypeEnum.chain:RetrievalQA > 2:RunTypeEnum.chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:RunTypeEnum.chain:RetrievalQA > 2:RunTypeEnum.chain:StuffDocumentsChain > 3:RunTypeEnum.chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Do the Cozy Comfort Pullover Set        have side pockets?\",\n",
      "  \"context\": \": 10\\nname: Cozy Comfort Pullover Set, Stripe\\ndescription: Perfect for lounging, this striped knit set lives up to its name. We used ultrasoft fabric and an easy design that's as comfortable at bedtime as it is when we have to make a quick run out.\\n\\nSize & Fit\\n- Pants are Favorite Fit: Sits lower on the waist.\\n- Relaxed Fit: Our most generous fit sits farthest from the body.\\n\\nFabric & Care\\n- In the softest blend of 63% polyester, 35% rayon and 2% spandex.\\n\\nAdditional Features\\n- Relaxed fit top with raglan sleeves and rounded hem.\\n- Pull-on pants have a wide elastic waistband and drawstring, side pockets and a modern slim leg.\\n\\nImported.<<<<>>>>>: 73\\nname: Cozy Cuddles Knit Pullover Set\\ndescription: Perfect for lounging, this knit set lives up to its name. We used ultrasoft fabric and an easy design that's as comfortable at bedtime as it is when we have to make a quick run out. \\n\\nSize & Fit \\nPants are Favorite Fit: Sits lower on the waist. \\nRelaxed Fit: Our most generous fit sits farthest from the body. \\n\\nFabric & Care \\nIn the softest blend of 63% polyester, 35% rayon and 2% spandex.\\n\\nAdditional Features \\nRelaxed fit top with raglan sleeves and rounded hem. \\nPull-on pants have a wide elastic waistband and drawstring, side pockets and a modern slim leg. \\nImported.<<<<>>>>>: 632\\nname: Cozy Comfort Fleece Pullover\\ndescription: The ultimate sweater fleece \\u2013 made from superior fabric and offered at an unbeatable price. \\n\\nSize & Fit\\nSlightly Fitted: Softly shapes the body. Falls at hip. \\n\\nWhy We Love It\\nOur customers (and employees) love the rugged construction and heritage-inspired styling of our popular Sweater Fleece Pullover and wear it for absolutely everything. From high-intensity activities to everyday tasks, you'll find yourself reaching for it every time.\\n\\nFabric & Care\\nRugged sweater-knit exterior and soft brushed interior for exceptional warmth and comfort. Made from soft, 100% polyester. Machine wash and dry.\\n\\nAdditional Features\\nFeatures our classic Mount Katahdin logo. Snap placket. Front princess seams create a feminine shape. Kangaroo handwarmer pockets. Cuffs and hem reinforced with jersey binding. Imported.\\n\\n \\u2013 Official Supplier to the U.S. Ski Team\\nTHEIR WILL TO WIN, WOVEN RIGHT IN. LEARN MORE<<<<>>>>>: 151\\nname: Cozy Quilted Sweatshirt\\ndescription: Our sweatshirt is an instant classic with its great quilted texture and versatile weight that easily transitions between seasons. With a traditional fit that is relaxed through the chest, sleeve, and waist, this pullover is lightweight enough to be worn most months of the year. The cotton blend fabric is super soft and comfortable, making it the perfect casual layer. To make dressing easy, this sweatshirt also features a snap placket and a heritage-inspired Mt. Katahdin logo patch. For care, machine wash and dry. Imported.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:RunTypeEnum.chain:RetrievalQA > 2:RunTypeEnum.chain:StuffDocumentsChain > 3:RunTypeEnum.chain:LLMChain > 4:RunTypeEnum.llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Use the following pieces of context to answer the users question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n: 10\\nname: Cozy Comfort Pullover Set, Stripe\\ndescription: Perfect for lounging, this striped knit set lives up to its name. We used ultrasoft fabric and an easy design that's as comfortable at bedtime as it is when we have to make a quick run out.\\n\\nSize & Fit\\n- Pants are Favorite Fit: Sits lower on the waist.\\n- Relaxed Fit: Our most generous fit sits farthest from the body.\\n\\nFabric & Care\\n- In the softest blend of 63% polyester, 35% rayon and 2% spandex.\\n\\nAdditional Features\\n- Relaxed fit top with raglan sleeves and rounded hem.\\n- Pull-on pants have a wide elastic waistband and drawstring, side pockets and a modern slim leg.\\n\\nImported.<<<<>>>>>: 73\\nname: Cozy Cuddles Knit Pullover Set\\ndescription: Perfect for lounging, this knit set lives up to its name. We used ultrasoft fabric and an easy design that's as comfortable at bedtime as it is when we have to make a quick run out. \\n\\nSize & Fit \\nPants are Favorite Fit: Sits lower on the waist. \\nRelaxed Fit: Our most generous fit sits farthest from the body. \\n\\nFabric & Care \\nIn the softest blend of 63% polyester, 35% rayon and 2% spandex.\\n\\nAdditional Features \\nRelaxed fit top with raglan sleeves and rounded hem. \\nPull-on pants have a wide elastic waistband and drawstring, side pockets and a modern slim leg. \\nImported.<<<<>>>>>: 632\\nname: Cozy Comfort Fleece Pullover\\ndescription: The ultimate sweater fleece \\u2013 made from superior fabric and offered at an unbeatable price. \\n\\nSize & Fit\\nSlightly Fitted: Softly shapes the body. Falls at hip. \\n\\nWhy We Love It\\nOur customers (and employees) love the rugged construction and heritage-inspired styling of our popular Sweater Fleece Pullover and wear it for absolutely everything. From high-intensity activities to everyday tasks, you'll find yourself reaching for it every time.\\n\\nFabric & Care\\nRugged sweater-knit exterior and soft brushed interior for exceptional warmth and comfort. Made from soft, 100% polyester. Machine wash and dry.\\n\\nAdditional Features\\nFeatures our classic Mount Katahdin logo. Snap placket. Front princess seams create a feminine shape. Kangaroo handwarmer pockets. Cuffs and hem reinforced with jersey binding. Imported.\\n\\n \\u2013 Official Supplier to the U.S. Ski Team\\nTHEIR WILL TO WIN, WOVEN RIGHT IN. LEARN MORE<<<<>>>>>: 151\\nname: Cozy Quilted Sweatshirt\\ndescription: Our sweatshirt is an instant classic with its great quilted texture and versatile weight that easily transitions between seasons. With a traditional fit that is relaxed through the chest, sleeve, and waist, this pullover is lightweight enough to be worn most months of the year. The cotton blend fabric is super soft and comfortable, making it the perfect casual layer. To make dressing easy, this sweatshirt also features a snap placket and a heritage-inspired Mt. Katahdin logo patch. For care, machine wash and dry. Imported.\\nHuman: Do the Cozy Comfort Pullover Set        have side pockets?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:RunTypeEnum.chain:RetrievalQA > 2:RunTypeEnum.chain:StuffDocumentsChain > 3:RunTypeEnum.chain:LLMChain > 4:RunTypeEnum.llm:ChatOpenAI] [545.447ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Yes, the Cozy Comfort Pullover Set does have side pockets on the pull-on pants.\",\n",
      "        \"generation_info\": null,\n",
      "        \"message\": {\n",
      "          \"content\": \"Yes, the Cozy Comfort Pullover Set does have side pockets on the pull-on pants.\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"example\": false\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 732,\n",
      "      \"completion_tokens\": 19,\n",
      "      \"total_tokens\": 751,\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"cached_tokens\": 0,\n",
      "        \"audio_tokens\": 0\n",
      "      },\n",
      "      \"completion_tokens_details\": {\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  }\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:RunTypeEnum.chain:RetrievalQA > 2:RunTypeEnum.chain:StuffDocumentsChain > 3:RunTypeEnum.chain:LLMChain] [548.9309999999999ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Yes, the Cozy Comfort Pullover Set does have side pockets on the pull-on pants.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:RunTypeEnum.chain:RetrievalQA > 2:RunTypeEnum.chain:StuffDocumentsChain] [581.152ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"Yes, the Cozy Comfort Pullover Set does have side pockets on the pull-on pants.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:RunTypeEnum.chain:RetrievalQA] [954.02ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"result\": \"Yes, the Cozy Comfort Pullover Set does have side pockets on the pull-on pants.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, the Cozy Comfort Pullover Set does have side pockets on the pull-on pants.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(examples[0][\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3d6bef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off the debug mode\n",
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bdbdce",
   "metadata": {},
   "source": [
    "## LLM assisted evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81db479f",
   "metadata": {},
   "source": [
    "17. create predictions for all the different examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4dca05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "predictions = qa.apply(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c0f75f",
   "metadata": {},
   "source": [
    "18. import the QA eval chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6012a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAEvalChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600e7589",
   "metadata": {},
   "source": [
    "19. create this chain with a language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "724b1c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=llm_model)\n",
    "eval_chain = QAEvalChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf41e6a",
   "metadata": {},
   "source": [
    "20. call evaluate on this chain, pass examples and predictions and get back a bunch of graded outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b46ae55",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +=: 'OpenAIObject' and 'OpenAIObject'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m graded_outputs = \u001b[43meval_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Endava-AI-Onboarding/langchain_course_2/.venv/lib/python3.11/site-packages/langchain/evaluation/qa/eval_chain.py:60\u001b[39m, in \u001b[36mQAEvalChain.evaluate\u001b[39m\u001b[34m(self, examples, predictions, question_key, answer_key, prediction_key)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Evaluate question answering examples and predictions.\"\"\"\u001b[39;00m\n\u001b[32m     51\u001b[39m inputs = [\n\u001b[32m     52\u001b[39m     {\n\u001b[32m     53\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m: example[question_key],\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(examples)\n\u001b[32m     58\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Endava-AI-Onboarding/langchain_course_2/.venv/lib/python3.11/site-packages/langchain/chains/llm.py:157\u001b[39m, in \u001b[36mLLMChain.apply\u001b[39m\u001b[34m(self, input_list, callbacks)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    156\u001b[39m     run_manager.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    158\u001b[39m outputs = \u001b[38;5;28mself\u001b[39m.create_outputs(response)\n\u001b[32m    159\u001b[39m run_manager.on_chain_end({\u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: outputs})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Endava-AI-Onboarding/langchain_course_2/.venv/lib/python3.11/site-packages/langchain/chains/llm.py:154\u001b[39m, in \u001b[36mLLMChain.apply\u001b[39m\u001b[34m(self, input_list, callbacks)\u001b[39m\n\u001b[32m    149\u001b[39m run_manager = callback_manager.on_chain_start(\n\u001b[32m    150\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m},\n\u001b[32m    151\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33minput_list\u001b[39m\u001b[33m\"\u001b[39m: input_list},\n\u001b[32m    152\u001b[39m )\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    156\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Endava-AI-Onboarding/langchain_course_2/.venv/lib/python3.11/site-packages/langchain/chains/llm.py:79\u001b[39m, in \u001b[36mLLMChain.generate\u001b[39m\u001b[34m(self, input_list, run_manager)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[32m     78\u001b[39m prompts, stop = \u001b[38;5;28mself\u001b[39m.prep_prompts(input_list, run_manager=run_manager)\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m     81\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Endava-AI-Onboarding/langchain_course_2/.venv/lib/python3.11/site-packages/langchain/chat_models/base.py:143\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    137\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    138\u001b[39m     prompts: List[PromptValue],\n\u001b[32m    139\u001b[39m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    140\u001b[39m     callbacks: Callbacks = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    141\u001b[39m ) -> LLMResult:\n\u001b[32m    142\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Endava-AI-Onboarding/langchain_course_2/.venv/lib/python3.11/site-packages/langchain/chat_models/base.py:92\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks)\u001b[39m\n\u001b[32m     90\u001b[39m     run_manager.on_llm_error(e)\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m llm_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_combine_llm_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mres\u001b[49m\u001b[43m.\u001b[49m\u001b[43mllm_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m generations = [res.generations \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[32m     94\u001b[39m output = LLMResult(generations=generations, llm_output=llm_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Endava-AI-Onboarding/langchain_course_2/.venv/lib/python3.11/site-packages/langchain/chat_models/openai.py:292\u001b[39m, in \u001b[36mChatOpenAI._combine_llm_outputs\u001b[39m\u001b[34m(self, llm_outputs)\u001b[39m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m token_usage.items():\n\u001b[32m    291\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m overall_token_usage:\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m         \u001b[43moverall_token_usage\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    294\u001b[39m         overall_token_usage[k] = v\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for +=: 'OpenAIObject' and 'OpenAIObject'"
     ]
    }
   ],
   "source": [
    "graded_outputs = eval_chain.evaluate(examples, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454f1735",
   "metadata": {},
   "source": [
    "21. to see what is going on with each example, we're going to loop through them\n",
    "- print out the Q, the real A (generated by llm), the predictive answer, and predicted grade (all generated by LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3437cfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "Question: Do the Cozy Comfort Pullover Set        have side pockets?\n",
      "Real Answer: Yes\n",
      "Predicted Answer: Yes, the Cozy Comfort Pullover Set does have side pockets.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'graded_outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mReal Answer: \u001b[39m\u001b[33m\"\u001b[39m + predictions[i][\u001b[33m'\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPredicted Answer: \u001b[39m\u001b[33m\"\u001b[39m + predictions[i][\u001b[33m'\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPredicted Grade: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[43mgraded_outputs\u001b[49m[i][\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[31mNameError\u001b[39m: name 'graded_outputs' is not defined"
     ]
    }
   ],
   "source": [
    "for i, eg in enumerate(examples):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"Question: \" + predictions[i]['query'])\n",
    "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
    "    print(\"Predicted Answer: \" + predictions[i]['result'])\n",
    "    print(\"Predicted Grade: \" + graded_outputs[i]['text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e132c55",
   "metadata": {},
   "source": [
    "22. let's look at the 1st example\n",
    "- answers are arbitrary strings, as long as they have the same semantic meaning they should be graded as similar\n",
    "- we need to create new evaluation metrics\n",
    "- we are using the llm to do the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d95133bb-43b6-441d-9ba5-00ef5609ccc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graded_outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgraded_outputs\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'graded_outputs' is not defined"
     ]
    }
   ],
   "source": [
    "graded_outputs[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
